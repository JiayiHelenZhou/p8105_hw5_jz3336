---
title: "P8105 Homework 5"
author: Jiayi Zhou
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
library(readxl)
set.seed(1)
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1: 

**Description on the raw dataset:**
This dataset contains homicides data in 50 cities in the U.S. There were 12 variable describing the characteristics of each victim in the raw data, including their name, age, sex, and the disposition status. There were 52179 entries in total.

**Import and organize data**
```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

**prop.test:**
using `prop.test` to get the proportion of unsolved homicides in Baltimore:
```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

run `prop.test` for each of the cities in the dataset:
```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

**plot with error bars:**
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2:

#### Tidy dataframe:

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time

```{r}
files= list.files("./data2")

read_listfiles = function(x) {
  path = str_c("./data2/",x)
  
  read_csv(path) %>% 
  janitor::clean_names()
}

tidy_df = 
  map_df(files, read_listfiles) %>% 
  mutate(files_names = files) %>% 
  relocate(files_names) %>% 
  separate(files_names, into = c("arms", "subject_id"), sep = c("_")) %>% 
  mutate(
    subject_id = str_remove(subject_id, ".csv"),
    subject_id = as.factor(subject_id),
    arms = recode_factor(arms,"con" = "control", "exp" = "experiment")) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "weeks",
    values_to = "observations"
  ) %>% 
  mutate(
    weeks = str_remove(weeks, "_"),
    weeks = as.factor(weeks))
```

#### Spaghetti plot

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.
```{r}
##tidy_df %>% 
##  interaction("arms", "subject_id")
```

```{r}
tidy_df %>%
  group_by(arms, subject_id) %>% 
  ggplot(aes(x = weeks, y = observations, group = interaction(arms, subject_id), color = arms)) +
  geom_line(size = 1) +
  labs(x = 'Week',
       y = 'Observation',
       title = 'Changes in Observation over an Eight Weeks Period')
```

__Comment:__
Observations in control group and experiment group started of at a similar value.However the observations in experiment group had an prominent increasing trend, which soon surpassed the observation values of control group over the eight weeks period. On the other hand, observation values in control group did not obvious changing trend.

